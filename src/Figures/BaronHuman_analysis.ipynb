{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of gene degree on Baron Human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyze the Baron Human WCSN to obtain the gene degree matrix for different cell types across folds, and identify the top 100 genes with the highest degree for each cell type in each fold.\n",
    "- For each cell type, obtain the union of the top 100 genes with the highest degree across different folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baron_Human degree matrix: Generate the gene degree matrix for each cell type and fold based on WCSN.\n",
    "! python get_degree_matrix.py -expr ../../dataset/pre_data/scRNAseq_datasets/Baron_Human.npz \\\n",
    "    -ca 0.01 -hvgs 2000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the seq_dict file containing label information\n",
    "seq_dict = np.load('../../dataset/pre_data/scRNAseq_datasets/Baron_Human/seq_dict.npz', allow_pickle=True) \n",
    "label = seq_dict['label']\n",
    "\n",
    "# Load the degree matrix file\n",
    "matrix_dict = np.load('../../dataset/5fold_data/Baron_Human/degree_matrix_Baron_Human_a0.01_hvgs2000.npz', allow_pickle=True)\n",
    "\n",
    "# Print the keys in the loaded matrix_dict\n",
    "print(\"Keys in loaded matrix_dict:\", matrix_dict.files)\n",
    "\n",
    "# Load str_labels (cell type labels)\n",
    "str_labels = matrix_dict['str_labels']\n",
    "print(\"cell-type: \", str_labels)\n",
    "\n",
    "# Ensure str_labels has the correct length\n",
    "print(\"Length of str_labels:\", len(str_labels))\n",
    "\n",
    "# Iterate over each cell type to access its degree matrix\n",
    "for k in range(len(str_labels)):\n",
    "    # Use the string form of k to access the degree matrix for each cell type\n",
    "    degree_matrix_key = f'{k}'  # Using string format for key\n",
    "    degree_matrix_dict = matrix_dict[degree_matrix_key].item()   # Unpack to a dictionary\n",
    "    print(degree_matrix_dict.keys())\n",
    "\n",
    "    # Create a DataFrame to store the top 100 indices (based on mean degree) for each fold\n",
    "    fold_top_indices_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate through each fold (1 to 5)\n",
    "    for i in range(5):\n",
    "        fold = i + 1\n",
    "        cur_fold_degree_matrix = degree_matrix_dict[f'CV_{fold}']\n",
    "        \n",
    "        # Compute the mean degree for each row (gene) in the degree matrix\n",
    "        mean_degree = np.mean(cur_fold_degree_matrix, axis=1)\n",
    "\n",
    "        # Sort and get the indices of the top 100 maximum values\n",
    "        top_100_indices = np.argsort(mean_degree)[-100:][::-1]  # Sort, select top 100, and reverse order\n",
    "\n",
    "        # Add the top 100 indices for the current fold to the DataFrame\n",
    "        fold_top_indices_df[f'Fold_{fold}'] = top_100_indices\n",
    "\n",
    "    # Save the top 100 indices for each fold as a .tsv file, with the filename based on the cell type\n",
    "    cell_type_name = str_labels[k]\n",
    "    tsv_filename = f'data/Baron_Human/Gene_degree/{cell_type_name}_top100_indices.tsv'\n",
    "    fold_top_indices_df.to_csv(tsv_filename, sep='\\t', index=False)\n",
    "\n",
    "    # Print confirmation message for the saved file\n",
    "    print(f\"Saved top 100 indices for cell type '{cell_type_name}' to {tsv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def read_and_union_tsv(cell_type):\n",
    "    \"\"\"\n",
    "    Read the TSV file for the specified cell type and return the union of top 100 genes across all folds.\n",
    "    \n",
    "    Parameters:\n",
    "    cell_type (str): The name of the cell type\n",
    "    \n",
    "    Returns:\n",
    "    list: A list containing the union of top 100 genes across all folds\n",
    "    \"\"\"\n",
    "    file_path = f'data/Baron_Human/Gene_degree/{cell_type}_top100_indices.tsv'\n",
    "    \n",
    "    try:\n",
    "        # Read the TSV file\n",
    "        data = pd.read_csv(file_path, sep='\\t')\n",
    "        # Get the union of all columns' unique values\n",
    "        # Use set.union to combine the unique values from all columns\n",
    "        union_set = set()\n",
    "        for col in data.columns:\n",
    "            union_set.update(data[col].dropna().astype(int))\n",
    "        \n",
    "        return list(union_set)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File not found for cell type {cell_type}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {cell_type}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def process_cell_types(str_labels):\n",
    "    \"\"\"\n",
    "    Process all cell types in the order provided by str_labels.\n",
    "    \n",
    "    Parameters:\n",
    "    str_labels (list): A list of all cell type names\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the union of top 100 genes for each cell type\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a dictionary to store results\n",
    "    result_dict = {}\n",
    "    \n",
    "    # Process each cell type in the provided order\n",
    "    for cell_type in str_labels:\n",
    "        union_genes = read_and_union_tsv(cell_type)\n",
    "        result_dict[cell_type] = pd.Series(union_genes, dtype='Int64')\n",
    "        print(f\"{cell_type}: {len(union_genes)} genes\")\n",
    "    \n",
    "    # Convert the result dictionary into a DataFrame\n",
    "    result_df = pd.DataFrame(result_dict)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Main execution flow\n",
    "\n",
    "# Load the seq_dict file containing the cell type labels\n",
    "seq_dict = np.load('../../dataset/5fold_data/Baron_Human/seq_dict.npz', allow_pickle=True) \n",
    "# label = seq_dict['label']  # label is not needed in this script\n",
    "str_labels = seq_dict['str_labels']\n",
    "\n",
    "# Process all cell types to get the union of top 100 genes\n",
    "result_df = process_cell_types(str_labels)\n",
    "\n",
    "# Save the result as a TSV file\n",
    "output_path = 'data/Baron_Human/Gene_degree/Baron_Human_merged_top100_genes.tsv'\n",
    "result_df.to_csv(output_path, sep='\\t', index=False)\n",
    "print(f\"\\nResults saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n",
      "['A2M' 'A4GALT' 'AACSP1' ... 'TIMM8A' 'TIMMDC1' 'TJP2']\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "seq_dict = np.load('../../dataset/5fold_data//Baron_Human/seq_dict.npz', allow_pickle=True) \n",
    "genes = seq_dict['gene_symbol']\n",
    "\n",
    "all_filtered_genes_file = '../../dataset/5fold_data/Baron_Human/Baron_Human_filtered_hvgs2000.npy'\n",
    "\n",
    "# 得到每一折的基因数量：\n",
    "# genes_num_all = get_gene_num(all_filtered_genes_file)\n",
    "all_filtered_genes_array = np.load(all_filtered_genes_file, allow_pickle=True)\n",
    "filtered_genes_index = all_filtered_genes_array[0]\n",
    "filtered_genes_index = filtered_genes_index.astype(int)\n",
    "print(filtered_genes_index.shape)\n",
    "\n",
    "filtered_genes = genes[filtered_genes_index]\n",
    "\n",
    "print(filtered_genes)\n",
    "print(filtered_genes.shape)\n",
    "df = pd.DataFrame(filtered_genes, columns=['gene_symbol'])\n",
    "df.to_csv('data/Baron_Human/Baron_Human_gene_symbol_hvgs2000.tsv',  sep='\\t', index=False, header=True)\n",
    "# print(f\"Successfully saved {len(genes)} genes to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of edge weight on Baron Human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyze the Baron Human WCSN to identify the top 100 edges with the highest weight for each cell type in each fold.\n",
    "- For each cell type, obtain the union of the top 100 edges with the highest weight across different folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from scipy import sparse\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_top_edges(matrices, top_k=100):\n",
    "    \"\"\"\n",
    "    Find the top edges with the highest average weight across multiple sparse matrices.\n",
    "    \n",
    "    Parameters:\n",
    "    matrices: List[scipy.sparse.csr_matrix] - List of sparse matrices\n",
    "    top_k: int - The number of top edges to return\n",
    "    \n",
    "    Returns:\n",
    "    List[tuple] - A list of (node1, node2, avg_weight) tuples sorted by average weight in descending order\n",
    "    \"\"\"\n",
    "    total_matrices = len(matrices)  # Total number of matrices\n",
    "    edge_weights = defaultdict(float)\n",
    "    \n",
    "    # Iterate over all matrices\n",
    "    for matrix in matrices:\n",
    "        # Get coordinates and values of non-zero elements\n",
    "        rows, cols = matrix.nonzero()\n",
    "        values = matrix.data\n",
    "        \n",
    "        # Iterate over each non-zero element\n",
    "        for i in range(len(rows)):\n",
    "            # Convert numpy integers to Python integers\n",
    "            node1 = int(min(rows[i], cols[i]))\n",
    "            node2 = int(max(rows[i], cols[i]))\n",
    "            if node1 != node2:  # Ignore self-loops\n",
    "                # Convert numpy floats to Python floats\n",
    "                edge_weights[(node1, node2)] += float(values[i])\n",
    "\n",
    "    # Compute average weight for each edge\n",
    "    edge_avg_weights = []\n",
    "    for (node1, node2), weight_sum in edge_weights.items():\n",
    "        # Ensure all values are Python native types\n",
    "        avg_weight = float(weight_sum) / float(total_matrices)\n",
    "        edge_avg_weights.append((int(node1), int(node2), float(avg_weight)))\n",
    "    \n",
    "    # Return the top k edges by average weight\n",
    "    return heapq.nlargest(top_k, edge_avg_weights, key=lambda x: x[2])\n",
    "\n",
    "\n",
    "def load_and_process_matrices(cell_test_folder, cur_label_idxs):\n",
    "    \"\"\"\n",
    "    Load sparse matrix data for the specified cells.\n",
    "    \n",
    "    Parameters:\n",
    "    file_paths: List[str] - List of sparse matrix file paths\n",
    "    \n",
    "    Returns:\n",
    "    List[scipy.sparse.csr_matrix] - List of sparse matrices\n",
    "    \"\"\"\n",
    "    matrices = []\n",
    "\n",
    "    for idx in cur_label_idxs:\n",
    "        data = torch.load(os.path.join(cell_test_folder, f'cell_{idx}.pt'))\n",
    "        # Get the current edge index and edge weight\n",
    "        edge_index = data.edge_index\n",
    "        edge_weight = data.edge_weight\n",
    "        \n",
    "        # Get the number of nodes\n",
    "        num_nodes = data.x.shape[0]  # Extract node count from feature matrix\n",
    "\n",
    "        # Convert edge_index and edge_weight to numpy arrays\n",
    "        edges = edge_index.cpu().numpy()\n",
    "        weights = edge_weight.cpu().numpy()\n",
    "\n",
    "        # Create sparse matrix from edge_index and edge_weight\n",
    "        sparse_mat = sparse.csr_matrix(\n",
    "            (weights, (edges[0], edges[1])),\n",
    "            shape=(num_nodes, num_nodes)\n",
    "        )           \n",
    "        \n",
    "        matrices.append(sparse_mat)     \n",
    "    \n",
    "    return matrices\n",
    "\n",
    "\n",
    "def save_cell_type_edges(cell_type, fold_edges, save_folder, base_filename):\n",
    "    \"\"\"\n",
    "    Save the top edges for each cell type across different folds.\n",
    "    \n",
    "    Parameters:\n",
    "    cell_type: str - The name of the cell type\n",
    "    fold_edges: dict - Dictionary containing the top edges for each fold\n",
    "    save_folder: str - Folder path where the results will be saved\n",
    "    base_filename: str - Base filename for naming the saved files\n",
    "    \"\"\"\n",
    "    # Create save directory if it doesn't exist\n",
    "    save_dir = os.path.join(save_folder, f\"{base_filename}_top_edges\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Build the file path for saving\n",
    "    filename = os.path.join(save_dir, f\"{cell_type}_top_edges.npz\")\n",
    "    \n",
    "    # Prepare dictionary for saving data\n",
    "    save_dict = {\n",
    "        'cell_type': cell_type,\n",
    "        'base_filename': base_filename\n",
    "    }\n",
    "    \n",
    "    # Add top edges for each fold to the dictionary\n",
    "    for fold_idx, edges in fold_edges.items():\n",
    "        # Convert edges to numpy array and ensure proper data types\n",
    "        edges_array = np.array(edges, dtype=[\n",
    "            ('node1', 'int32'), \n",
    "            ('node2', 'int32'), \n",
    "            ('weight', 'float32')\n",
    "        ])\n",
    "        save_dict[f'fold_{fold_idx}_edges'] = edges_array        \n",
    "    \n",
    "    # Save the data as a .npz file\n",
    "    np.savez(filename, **save_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dict = np.load('../../dataset/5fold_data//Baron_Human/seq_dict.npz', allow_pickle=True) \n",
    "label = seq_dict['label'] \n",
    "str_labels = seq_dict['str_labels']\n",
    "save_folder = 'data/Baron_Human/'\n",
    "\n",
    "# Create a dictionary to store the top edges for all folds for each cell type\n",
    "cell_type_edges = {}\n",
    "\n",
    "# Iterate through each cell type\n",
    "for cur_label, cell_type in enumerate(str_labels):\n",
    "    print(\"cur_label: \", cur_label)\n",
    "    print(\"cell_type: \", cell_type)\n",
    "\n",
    "    # Dictionary to store top edges for each fold of the current cell type\n",
    "    fold_edges = {}\n",
    "    \n",
    "    # Iterate through each fold (1 to 5)\n",
    "    for k in range(5):\n",
    "        k_fold = k + 1\n",
    "        test_index = seq_dict[f'test_index_{k_fold}']\n",
    "        label_test = label[test_index]\n",
    "        cur_label_idxs = np.where(label_test == cur_label)[0].tolist()\n",
    "\n",
    "        # Define the folder containing the processed data for the current fold\n",
    "        cell_test_folder = os.path.join(\n",
    "            \"../../dataset/5fold_data/Baron_Human/wcsn_a0.01_hvgs2000\", \n",
    "            f\"test_f{k_fold}\", \n",
    "            'processed'\n",
    "        )\n",
    "        \n",
    "        # Load the matrices for the current fold and find the top edges\n",
    "        cur_mat = load_and_process_matrices(cell_test_folder, cur_label_idxs)\n",
    "        cur_top_edges = find_top_edges(cur_mat)\n",
    "        \n",
    "        # Store the top edges for the current fold\n",
    "        fold_edges[k_fold] = cur_top_edges\n",
    "    \n",
    "    # Save the top edges for all folds for the current cell type\n",
    "    save_cell_type_edges(cell_type, fold_edges, save_folder,  base_filename=\"Baron_Human\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 files to process\n",
      "Successfully processed acinar\n",
      "Successfully processed activated_stellate\n",
      "Successfully processed alpha\n",
      "Successfully processed beta\n",
      "Successfully processed delta\n",
      "Successfully processed ductal\n",
      "Successfully processed endothelial\n",
      "Successfully processed epsilon\n",
      "Successfully processed gamma\n",
      "Successfully processed macrophage\n",
      "Successfully processed mast\n",
      "Successfully processed quiescent_stellate\n",
      "Successfully processed schwann\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def create_edge_strings(edges):\n",
    "    \"\"\"Convert edge pairs to string format.\"\"\"\n",
    "    return [f\"{int(edge[0])}-{int(edge[1])}\" for edge in edges]\n",
    "\n",
    "def process_npz_file(file_path):\n",
    "    \"\"\"Process a single npz file and save results.\"\"\"\n",
    "    # Extract cell type name from file path\n",
    "    cell_type = os.path.basename(file_path).replace('_top_edges.npz', '')\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = os.path.join(os.path.dirname(file_path), f'{cell_type}_top_edges')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load and process data\n",
    "    try:\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        \n",
    "        # Process each fold\n",
    "        for i in range(1, 6):  # 5-fold\n",
    "            fold_key = f'fold_{i}_edges'\n",
    "            if fold_key in data:\n",
    "                edges = data[fold_key]\n",
    "                edge_strings = create_edge_strings(edges)\n",
    "                \n",
    "                # Save to CSV\n",
    "                output_file = os.path.join(output_dir, f'fold_{i}_edges.csv')\n",
    "                pd.DataFrame({'edges': edge_strings}).to_csv(output_file, index=False)\n",
    "                \n",
    "        print(f\"Successfully processed {cell_type}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {cell_type}: {str(e)}\")\n",
    "\n",
    "def process_all_cell_types(base_dir):\n",
    "    \"\"\"Process all npz files in the directory.\"\"\"\n",
    "    # Find all npz files in the directory\n",
    "    npz_files = glob.glob(os.path.join(base_dir, '*_top_edges.npz'))\n",
    "    \n",
    "    if not npz_files:\n",
    "        print(f\"No npz files found in {base_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(npz_files)} files to process\")\n",
    "    \n",
    "    # Process each file\n",
    "    for file_path in npz_files:\n",
    "        process_npz_file(file_path)\n",
    "    \n",
    "    print(\"Processing complete!\")\n",
    "\n",
    "# # Main execution\n",
    "# if __name__ == \"__main__\":\n",
    "base_dir = 'data/Baron_Human/Baron_Human_top_edges'\n",
    "process_all_cell_types(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_union_edges(npz_file):\n",
    "   \"\"\"Get the union of top edges across all 5 folds for a specific cell type.\"\"\"\n",
    "   # Load the npz file\n",
    "   data = np.load(npz_file, allow_pickle=True)\n",
    "   \n",
    "   # Set to store all edges\n",
    "   all_edges = set()\n",
    "   \n",
    "   # Iterate through the 5 folds\n",
    "   for i in range(1, 6):\n",
    "       fold_key = f'fold_{i}_edges'\n",
    "       if fold_key in data:\n",
    "           edges = data[fold_key]\n",
    "           # Convert each edge to string format and add to the set\n",
    "           edge_strings = [f\"{int(edge[0])}-{int(edge[1])}\" for edge in edges]\n",
    "           all_edges.update(edge_strings)\n",
    "   print(list(all_edges))\n",
    "   return sorted(list(all_edges))  # Return the sorted list of edges\n",
    "\n",
    "\n",
    "# Load the seq_dict file containing the labels for cell types\n",
    "seq_dict = np.load('../../dataset/5fold_data/Baron_Human/seq_dict.npz', allow_pickle=True) \n",
    "str_labels = seq_dict['str_labels']\n",
    "\n",
    "cell_types = str_labels.tolist()  # Actual cell type names\n",
    "print(\"cell types: \", cell_types)\n",
    "\n",
    "# Dictionary to store union of edges for each cell type\n",
    "edges_dict = {}\n",
    "\n",
    "# Iterate through each cell type and process their corresponding npz files\n",
    "for cell_type in cell_types:\n",
    "   npz_file = f'data/Baron_Human/Baron_Human_top_edges/{cell_type}_top_edges.npz'  # Path to npz file\n",
    "   if os.path.exists(npz_file):\n",
    "        edges_dict[cell_type] = get_union_edges(npz_file)\n",
    "\n",
    "# Find the maximum length among all edge lists\n",
    "max_length = max(len(edges) for edges in edges_dict.values())\n",
    "\n",
    "# Pad the shorter lists with empty values to match the maximum length\n",
    "for cell_type in edges_dict:\n",
    "   if len(edges_dict[cell_type]) < max_length:\n",
    "       edges_dict[cell_type].extend([''] * (max_length - len(edges_dict[cell_type])))\n",
    "\n",
    "# Create a DataFrame from the edges dictionary\n",
    "df = pd.DataFrame(edges_dict)\n",
    "print(df.columns)\n",
    "\n",
    "# Save the DataFrame to a TSV file\n",
    "save_path = 'data/Baron_Human/Baron_Human_top_edges/union_edges.tsv'\n",
    "df.to_csv(save_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Save completed: {save_path}\")\n",
    "\n",
    "# Print some basic statistics\n",
    "print(\"\\nNumber of edges for each cell type:\")\n",
    "\n",
    "for cell_type in cell_types:\n",
    "   # Count the number of non-empty values\n",
    "   edge_count = len([x for x in edges_dict[cell_type] if x != ''])\n",
    "   print(f\"{cell_type}: {edge_count} edges\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data prepare for Figure 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyze the hub genes specific to each cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import os\n",
    "pathjoin = os.path.join\n",
    "\n",
    "# Load the seq_dict file containing label and str_labels\n",
    "seq_dict = np.load('../../dataset/5fold_data/Baron_Human/seq_dict.npz', allow_pickle=True) \n",
    "label = seq_dict['label']\n",
    "str_labels = seq_dict['str_labels']\n",
    "\n",
    "cur_label = 0\n",
    "matrix_dict = {}\n",
    "matrix_dict['str_labels'] = str_labels\n",
    "\n",
    "# Dictionary to store degree matrices for each fold\n",
    "degree_matrices_for_folds = {}  # Stores the degree matrices for each fold    \n",
    "\n",
    "# Iterate through each fold (1 to 5)\n",
    "for k in range(5):\n",
    "    k_fold = k + 1\n",
    "    test_index = seq_dict[f'test_index_{k_fold}']\n",
    "    label_test = label[test_index]\n",
    "\n",
    "    # Define the folder where processed cell data is stored for the current fold\n",
    "    cell_test_folder = f'../../dataset/5fold_data/Baron_Human/wcsn_a0.01_hvgs2000/test_f{k_fold}/processed'\n",
    "    \n",
    "    degree_matrix = []\n",
    "    print(test_index.shape)\n",
    "    # Iterate over the indices in the current test set\n",
    "    for idx in range(len(test_index)):\n",
    "        data = torch.load(os.path.join(cell_test_folder, f'cell_{idx}.pt'))\n",
    "        \n",
    "        # Get the edge indices and edge weights\n",
    "        edge_index = data.edge_index\n",
    "        edge_weight = data.edge_weight\n",
    "        \n",
    "        # Generate symmetric edge indices\n",
    "        row, col = edge_index\n",
    "        symmetric_edge_index = torch.cat([edge_index, torch.stack([col, row])], dim=1)\n",
    "        \n",
    "        # Calculate the degree (gene degree) for each node\n",
    "        degrees = torch.bincount(symmetric_edge_index[0])\n",
    "        \n",
    "        # If the number of nodes is less than the maximum number of genes (2000), pad with zeros\n",
    "        if degrees.size(0) < 2000:\n",
    "            degrees = torch.cat([degrees, torch.zeros(2000 - degrees.size(0))])\n",
    "        \n",
    "        # Add the degree vector to the degree matrix\n",
    "        degree_matrix.append(degrees.numpy())\n",
    "\n",
    "    # Transpose the degree matrix and store it in the dictionary\n",
    "    degree_matrix = np.array(degree_matrix).T\n",
    "    print(degree_matrix.shape)\n",
    "    degree_matrices_for_folds[f'CV_{k_fold}'] = degree_matrix  # Store the degree matrix for each fold\n",
    "\n",
    "# Save the degree matrices to a file\n",
    "degree_file = pathjoin('data/Baron_Human', f'degree_matrix_Baron_Human_per_fold_a0.01_hvgs2000.npz')\n",
    "\n",
    "# Check the structure of the degree_matrices_for_folds dictionary\n",
    "print(f\"Matrix dict structure before saving: {type(degree_matrices_for_folds)}\")\n",
    "for key in degree_matrices_for_folds:\n",
    "    print(f\"Key: {key}, Type: {type(degree_matrices_for_folds[key])}\")\n",
    "    if isinstance(degree_matrices_for_folds[key], dict):  # Ensure it is a dictionary\n",
    "        for inner_key in degree_matrices_for_folds[key]:\n",
    "            print(f\"  Inner Key: {inner_key}, Type: {type(degree_matrices_for_folds[key][inner_key])}\")\n",
    "\n",
    "# Save the degree matrices dictionary as a .npz file\n",
    "np.savez(degree_file, **degree_matrices_for_folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File containing the union of top 100 genes for different cell types\n",
    "Baron_Human_union_top_100_genes_file = 'Tables/Baron_Human/Gene_degree/Baron_Human_merged_top100_genes.tsv'\n",
    "Baron_Human_union_genes = pd.read_csv(Baron_Human_union_top_100_genes_file, sep='\\t', dtype=str, header=0)\n",
    "print(Baron_Human_union_genes.iloc[:5, :5])\n",
    "columns = Baron_Human_union_genes.columns.tolist()\n",
    "\n",
    "sets = {}\n",
    "# Create a set for each cell type's top 100 genes\n",
    "for col in columns:\n",
    "    sets[col] = set(Baron_Human_union_genes[col].dropna().values)\n",
    "\n",
    "# Calculate unique genes for each cell type\n",
    "unique_genes = {}\n",
    "for col in columns:\n",
    "    print(\"Current cell type: \", col)\n",
    "    # Calculate genes that only appear in the current cell type's set\n",
    "    unique = sets[col] - set.union(*[sets[c] for c in columns if c != col])\n",
    "    unique_genes[col] = unique\n",
    "    print(f\"\\nNumber of unique genes only in {col}: {len(unique)}\")\n",
    "    if len(unique) > 0:\n",
    "        print(\"List of unique genes:\")\n",
    "        print(unique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyze the high weight edges specific to each cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_union_edges(npz_file):\n",
    "   \"\"\"Get the union of top edges across all 5 folds for a specific cell type.\"\"\"\n",
    "   # Load the npz file\n",
    "   data = np.load(npz_file, allow_pickle=True)\n",
    "   \n",
    "   # Set to store all edges\n",
    "   all_edges = set()\n",
    "   \n",
    "   # Iterate through the 5 folds\n",
    "   for i in range(1, 6):\n",
    "       fold_key = f'fold_{i}_edges'\n",
    "       if fold_key in data:\n",
    "           edges = data[fold_key]\n",
    "           # Convert each edge to string format and add to the set\n",
    "           edge_strings = [f\"{int(edge[0])}-{int(edge[1])}\" for edge in edges]\n",
    "           all_edges.update(edge_strings)\n",
    "   print(list(all_edges))\n",
    "   return sorted(list(all_edges))  # Return the sorted list of edges\n",
    "\n",
    "\n",
    "# Load seq_dict file containing metadata for the cells\n",
    "seq_dict_file = '../../dataset/5fold_data//Baron_Human/seq_dict.npz'\n",
    "seq_dict = np.load(seq_dict_file, allow_pickle=True) \n",
    "# genes_id = seq_dict['gene_id']  # genes_id not used in this script\n",
    "label = seq_dict['label']\n",
    "str_labels = seq_dict['str_labels']\n",
    "\n",
    "# Process the three cell types\n",
    "cell_types = str_labels.tolist()  # Replace with actual cell type names\n",
    "edges_dict = {}\n",
    "\n",
    "# Iterate through each cell type and process its corresponding top edges file\n",
    "for cell_type in cell_types:\n",
    "   npz_file = f'data/Baron_Human/Baron_Human_top_edges/{cell_type}_top_edges.npz'  # Path to npz file\n",
    "   if os.path.exists(npz_file):\n",
    "        edges_dict[cell_type] = get_union_edges(npz_file)\n",
    "\n",
    "# Find the length of the longest list\n",
    "max_length = max(len(edges) for edges in edges_dict.values())\n",
    "\n",
    "# Pad the shorter lists with empty values to match the maximum length\n",
    "for cell_type in edges_dict:\n",
    "   if len(edges_dict[cell_type]) < max_length:\n",
    "       edges_dict[cell_type].extend([''] * (max_length - len(edges_dict[cell_type])))\n",
    "\n",
    "# Create a DataFrame from the edges dictionary\n",
    "df = pd.DataFrame(edges_dict)\n",
    "print(df.columns)\n",
    "\n",
    "# Save the DataFrame as a TSV file\n",
    "save_path = 'data/Baron_Human/Baron_Human_top_edges/union_edges.tsv'\n",
    "df.to_csv(save_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Save completed: {save_path}\")\n",
    "\n",
    "# Print some basic statistics\n",
    "print(\"\\nNumber of edges for each cell type:\")\n",
    "\n",
    "for cell_type in cell_types:\n",
    "   # Count the number of non-empty values\n",
    "   edge_count = len([x for x in edges_dict[cell_type] if x != ''])\n",
    "   print(f\"{cell_type}: {edge_count} edges\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Baron_Human_union_edges_file = 'data/Baron_Human/Baron_Human_top_edges/union_edges.tsv'\n",
    "Baron_Human_union_edges = pd.read_csv(Baron_Human_union_edges_file, sep='\\t', header=0)\n",
    "print(Baron_Human_union_edges)\n",
    "columns = Baron_Human_union_edges.columns.tolist()\n",
    "\n",
    "sets = {}\n",
    "# Create a set for each column of edges\n",
    "for col in columns:\n",
    "    sets[col] = set(Baron_Human_union_edges[col].dropna().values)\n",
    "\n",
    "# Print the size of each set\n",
    "print(\"\\nSize of each set:\")\n",
    "for col, s in sets.items():\n",
    "    print(f\"{col}: {len(s)} edges\")\n",
    "\n",
    "# Calculate the unique edges for cell type\n",
    "unique_edges = {}\n",
    "for col in columns:\n",
    "    # Compute edges that only appear in the current set\n",
    "    unique = sets[col] - set.union(*[sets[c] for c in columns if c != col])\n",
    "    unique_edges[col] = unique\n",
    "    print(f\"\\nNumber of unique edges only in {col}: {len(unique)}\")\n",
    "    if len(unique) > 0:\n",
    "        print(\"List of unique edges:\")\n",
    "        print(unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get the union of the edges\n",
    "all_edges = set.union(*sets.values())\n",
    "\n",
    "# Function to extract node indices from edge strings\n",
    "def extract_node_indices(edge_str):\n",
    "    # Split the string and convert to integers\n",
    "    node1, node2 = edge_str.split('-')\n",
    "    return int(node1), int(node2)\n",
    "\n",
    "# Create a list to store all node indices\n",
    "all_nodes = set()\n",
    "edge_pairs = []\n",
    "\n",
    "# Process each edge and extract the nodes\n",
    "for edge_str in all_edges:\n",
    "    node1, node2 = extract_node_indices(edge_str)\n",
    "    edge_pairs.append((node1, node2))\n",
    "    all_nodes.add(node1)\n",
    "    all_nodes.add(node2)\n",
    "\n",
    "# Convert the edge pairs to a numpy array for further processing\n",
    "edge_array = np.array(edge_pairs)\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\nTotal number of edges: {len(all_edges)}\")\n",
    "print(f\"Number of unique nodes involved: {len(all_nodes)}\")\n",
    "\n",
    "# Create a DataFrame to display the edge pairs\n",
    "edges_df = pd.DataFrame(edge_pairs, columns=['Node1', 'Node2'])\n",
    "print(\"\\nExample of the first few edges:\")\n",
    "print(edges_df.head())\n",
    "\n",
    "# Get the sorted list of unique node indices\n",
    "unique_nodes = sorted(list(all_nodes))\n",
    "print(\"\\nList of node indices (first 10):\")\n",
    "print(unique_nodes[:10])\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(f\"Minimum node index: {min(all_nodes)}\")\n",
    "print(f\"Maximum node index: {max(all_nodes)}\")\n",
    "\n",
    "# Provide the same analysis for each original set\n",
    "print(\"\\nDetailed information for each set:\")\n",
    "for col in columns:\n",
    "    current_edges = sets[col]\n",
    "    current_nodes = set()\n",
    "    for edge_str in current_edges:\n",
    "        node1, node2 = extract_node_indices(edge_str)\n",
    "        current_nodes.add(node1)\n",
    "        current_nodes.add(node2)\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"Number of edges: {len(current_edges)}\")\n",
    "    print(f\"Number of nodes: {len(current_nodes)}\")\n",
    "\n",
    "# Return the main data structures for further use\n",
    "result = {\n",
    "    'edge_pairs': edge_array,  # Edge pairs as a numpy array\n",
    "    'node_set': all_nodes,     # Set of all nodes\n",
    "    'edges_df': edges_df       # DataFrame of edge list\n",
    "}\n",
    "\n",
    "# Save the edge list DataFrame to a TSV file\n",
    "edges_df.to_csv('data/Baron_Human/Baron_Human_top_edges/all_union_edges.tsv', sep='\\t', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "def process_cell_graph(cell_data, target_edges):\n",
    "    \"\"\"Process the graph data of a single cell and extract the weights of target edges.\n",
    "    Args:\n",
    "        cell_data: Graph data containing edge_index and edge_weight\n",
    "        target_edges: DataFrame containing the target edges (Node1, Node2) where Node1 < Node2\n",
    "    Returns:\n",
    "        np.array: Array of edge weights for the target edges\n",
    "    \"\"\"\n",
    "    # Get edge indices and weights from the cell data\n",
    "    edge_index = cell_data.edge_index\n",
    "    edge_weight = cell_data.edge_weight\n",
    "    \n",
    "    # Create a dictionary mapping edges to their corresponding weights\n",
    "    edge_weight_dict = dict(zip(\n",
    "        [f\"{src}-{dst}\" for src, dst in zip(edge_index[0].tolist(), edge_index[1].tolist())],\n",
    "        edge_weight.tolist()\n",
    "    ))\n",
    "    \n",
    "    # Get the weights for the target edges\n",
    "    edge_weights = [\n",
    "        edge_weight_dict.get(f\"{row['Node1']}-{row['Node2']}\", 0.0) \n",
    "        for _, row in target_edges.iterrows()\n",
    "    ]\n",
    "    \n",
    "    return np.array(edge_weights)\n",
    "\n",
    "\n",
    "def extract_edge_weights(seq_dict_file, edges_df, gene_hvgs, batch_size=100):\n",
    "    \"\"\"Extract edge weight matrices for all folds.\"\"\"\n",
    "    # Load the sequence dictionary\n",
    "    seq_dict = np.load(seq_dict_file, allow_pickle=True)\n",
    "    edge_weight_matrices = {}\n",
    "\n",
    "    # Generate column names using gene pairs\n",
    "    column_names = [f\"{row['Node1']}-{row['Node2']}\" \n",
    "                   for _, row in edges_df.iterrows()]\n",
    "\n",
    "    # Process each fold (1 to 5)\n",
    "    for k in range(5):\n",
    "        k_fold = k + 1\n",
    "        print(f\"\\nProcessing Fold {k_fold}...\")\n",
    "        \n",
    "        # Get the test indices for the current fold\n",
    "        test_index = seq_dict[f'test_index_{k_fold}']\n",
    "        \n",
    "        # Define the path to the processed data folder\n",
    "        cell_test_folder = f'../../dataset/5fold_data/Baron_Human/wcsn_a0.01_hvgs2000_/test_f{k_fold}/processed'\n",
    "        \n",
    "        # Initialize the matrix to store edge weights for the current fold\n",
    "        edge_weight_matrix = []\n",
    "        \n",
    "        # Process the data in batches\n",
    "        for i in tqdm(range(0, len(test_index), batch_size), desc=f\"Fold {k_fold}\"):\n",
    "            batch_indices = range(i, min(i + batch_size, len(test_index)))\n",
    "            batch_weights = []\n",
    "            \n",
    "            for idx in batch_indices:\n",
    "                # Load cell data\n",
    "                cell_data = torch.load(os.path.join(cell_test_folder, f'cell_{idx}.pt'))\n",
    "                # Process the graph data for the current cell\n",
    "                cell_edge_weights = process_cell_graph(cell_data, edges_df)\n",
    "                batch_weights.append(cell_edge_weights)\n",
    "            \n",
    "            # Add the batch results to the main matrix\n",
    "            edge_weight_matrix.extend(batch_weights)\n",
    "\n",
    "        # Convert the matrix to a DataFrame\n",
    "        df = pd.DataFrame(edge_weight_matrix, columns=column_names)\n",
    "        \n",
    "        # Set the cell barcodes as the index\n",
    "        df.index = barcodes[test_index]\n",
    "        \n",
    "        edge_weight_matrices[f'CV_{k_fold}'] = df\n",
    "        \n",
    "        print(f\"Fold {k_fold} DataFrame shape: {df.shape}\")\n",
    "        print(f\"Memory usage: {df.memory_usage().sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    return edge_weight_matrices\n",
    "\n",
    "# Main program execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Set file paths\n",
    "    seq_dict_file = '../../dataset/5fold_data//Baron_Human/seq_dict.npz'\n",
    "    output_file = 'data/Baron_Human/edge_weight_matrices_Baron_Human_per_fold_a0.01_hvgs2000.h5'\n",
    "    \n",
    "    # Load gene symbols\n",
    "    seq_dict = np.load(seq_dict_file, allow_pickle=True) \n",
    "    genes = seq_dict['gene_symbol']\n",
    "\n",
    "    # Load filtered genes data\n",
    "    all_filtered_genes_file = '../../dataset/5fold_data/Baron_Human/Baron_Human_filtered_hvgs2000.npy'\n",
    "\n",
    "    # Load the filtered gene indices\n",
    "    all_filtered_genes_array = np.load(all_filtered_genes_file, allow_pickle=True)\n",
    "    filtered_genes_index = all_filtered_genes_array[0]\n",
    "    filtered_genes_index = filtered_genes_index.astype(int)\n",
    "    print(filtered_genes_index.shape)\n",
    "\n",
    "    # Extract the highly variable genes\n",
    "    gene_hvgs = genes[filtered_genes_index]\n",
    "\n",
    "    # Extract edge weight matrices for all folds\n",
    "    edge_weight_matrices = extract_edge_weights(seq_dict_file, edges_df, gene_hvgs)\n",
    "    \n",
    "    # Save the matrices as HDF5 files\n",
    "    with pd.HDFStore(output_file, mode='w') as store:\n",
    "        for fold, df in edge_weight_matrices.items():\n",
    "            store[fold] = df\n",
    "    print(f\"\\nResults saved to: {output_file}\")\n",
    "    \n",
    "    # Verify the saved results\n",
    "    print(\"\\nVerifying saved DataFrames:\")\n",
    "    with pd.HDFStore(output_file, mode='r') as store:\n",
    "        for fold in store.keys():\n",
    "            df = store[fold]\n",
    "            print(f\"\\n{fold}:\")\n",
    "            print(f\"Shape: {df.shape}\")\n",
    "            print(f\"Columns (first 5): {df.columns[:5]}\")\n",
    "            print(f\"Index (first 5): {df.index[:5]}\")\n",
    "            print(f\"Memory usage: {df.memory_usage().sum() / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 5N, Upset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from upsetplot import from_memberships\n",
    "from upsetplot import UpSet\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "file_path = \"data/Baron_Human/Gene_degree/Baron_Human_merged_top100_genes.tsv\"\n",
    "data = pd.read_csv(file_path, sep=\"\\t\", header=0, na_values=\"NA\")\n",
    "\n",
    "\n",
    "cell_type_sets = {}\n",
    "for column in data.columns:\n",
    "    genes = set(data[column].dropna().values)\n",
    "    cell_type_sets[column] = genes\n",
    "\n",
    "all_genes = list(set.union(*cell_type_sets.values()))\n",
    "cell_types = list(cell_type_sets.keys())\n",
    "binary_matrix = pd.DataFrame(0, index=all_genes, columns=cell_types)\n",
    "\n",
    "for gene in all_genes:\n",
    "    for cell_type in cell_types:\n",
    "        if gene in cell_type_sets[cell_type]:\n",
    "            binary_matrix.loc[gene, cell_type] = 1\n",
    "\n",
    "combinations = binary_matrix.apply(tuple, axis=1)\n",
    "combination_counts = combinations.value_counts()\n",
    "\n",
    "membership_lists = []\n",
    "for comb in combination_counts.index:\n",
    "    current_members = []\n",
    "    for i, v in enumerate(comb):\n",
    "        if v:\n",
    "            current_members.append(cell_types[i])\n",
    "    membership_lists.append(current_members)\n",
    "\n",
    "upset_data = from_memberships(\n",
    "    membership_lists,\n",
    "    data=combination_counts.values\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(3, 1))\n",
    "\n",
    "upset = UpSet(upset_data,\n",
    "              min_subset_size=3,\n",
    "              show_counts=True,\n",
    "              sort_by='cardinality',\n",
    "              element_size=20,\n",
    "              facecolor='#34495e',           \n",
    "              other_dots_color=0.3,          \n",
    "              shading_color='#f5f6fa',\n",
    "              )       \n",
    "\n",
    "upset.plot()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../../result/Figures/Figure_5N.png', dpi=1200, bbox_inches='tight',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 6N, Upset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from upsetplot import from_memberships\n",
    "from upsetplot import UpSet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "file_path = \"data/Baron_Human/Baron_Human_top_edges/union_edges.tsv\"\n",
    "data = pd.read_csv(file_path, sep=\"\\t\", header=0, na_values=\"NA\")\n",
    "cell_type_sets = {}\n",
    "for column in data.columns:\n",
    "    genes = set(data[column].dropna().values)\n",
    "    cell_type_sets[column] = genes\n",
    "\n",
    "all_genes = list(set.union(*cell_type_sets.values()))\n",
    "cell_types = list(cell_type_sets.keys())\n",
    "binary_matrix = pd.DataFrame(0, index=all_genes, columns=cell_types)\n",
    "\n",
    "for gene in all_genes:\n",
    "    for cell_type in cell_types:\n",
    "        if gene in cell_type_sets[cell_type]:\n",
    "            binary_matrix.loc[gene, cell_type] = 1\n",
    "\n",
    "combinations = binary_matrix.apply(tuple, axis=1)\n",
    "combination_counts = combinations.value_counts()\n",
    "\n",
    "membership_lists = []\n",
    "for comb in combination_counts.index:\n",
    "    current_members = []\n",
    "    for i, v in enumerate(comb):\n",
    "        if v:\n",
    "            current_members.append(cell_types[i])\n",
    "    membership_lists.append(current_members)\n",
    "\n",
    "upset_data = from_memberships(\n",
    "    membership_lists,\n",
    "    data=combination_counts.values\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "upset = UpSet(upset_data,\n",
    "              min_subset_size=3,\n",
    "              show_counts=True,\n",
    "              sort_by='cardinality',\n",
    "              element_size=20,\n",
    "              facecolor='#34495e',           \n",
    "              other_dots_color=0.3,         \n",
    "              shading_color='#f5f6fa',\n",
    "              )      \n",
    "\n",
    "upset.plot()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../result/Figures/Figure_6N.svg', dpi=1200, bbox_inches='tight',format='svg')\n",
    "plt.savefig('../../result/Figures/Figure_6N.png', dpi=1200, bbox_inches='tight',format='png')\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p38tor112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
