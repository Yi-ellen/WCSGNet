{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of gene degree on AMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the gene degree matrix for each cell type and each fold based on WCSN for AMB.\n",
    "! python get_degree_matrix.py -expr ../../dataset/pre_data/scRNAseq_datasets/AMB.npz \\\n",
    "    -ca 0.01 -hvgs 2000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the indices of the top 100 high-degree genes for each fold of all cell types.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load seq_dict file\n",
    "seq_dict = np.load('../../dataset/5fold_data/AMB/seq_dict.npz', allow_pickle=True) \n",
    "label = seq_dict['label']\n",
    "\n",
    "# Load degree matrix file\n",
    "matrix_dict = np.load('../../dataset/5fold_data/AMB/degree_matrix_AMB_a0.01_hvgs2000.npz', allow_pickle=True)\n",
    "\n",
    "# Print keys in the loaded matrix_dict\n",
    "print(\"Keys in loaded matrix_dict:\", matrix_dict.files)\n",
    "\n",
    "# Read str_labels from the matrix_dict\n",
    "str_labels = matrix_dict['str_labels']\n",
    "\n",
    "# Check the length of str_labels\n",
    "print(\"Length of str_labels:\", len(str_labels))\n",
    "\n",
    "# Access degree matrix for each cell type\n",
    "for k in range(len(str_labels)):\n",
    "    # Access degree matrix using string key\n",
    "    degree_matrix_key = f'{k}'  # Use the string form of k as the key\n",
    "    degree_matrix_dict = matrix_dict[degree_matrix_key].item()  # Unpack to dictionary\n",
    "    print(degree_matrix_dict.keys())  # Print keys of the current degree matrix dictionary\n",
    "\n",
    "    # Create a DataFrame to store top 100 mean indices for each fold\n",
    "    fold_top_indices_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(5):\n",
    "        fold = i + 1\n",
    "        cur_fold_degree_matrix = degree_matrix_dict[f'CV_{fold}']  # Access current fold's degree matrix\n",
    "\n",
    "        mean_degree = np.mean(cur_fold_degree_matrix, axis=1)  # Compute mean for each row\n",
    "\n",
    "        # Get top 100 indices with the highest mean values\n",
    "        top_100_indices = np.argsort(mean_degree)[-100:][::-1]  # Sort, take the last 100, and reverse order\n",
    "\n",
    "        # Print results\n",
    "        print(\"Mean values per row:\", mean_degree)\n",
    "        print(\"Top 100 indices with highest mean values:\", top_100_indices)\n",
    "        \n",
    "        # Add the top 100 indices for the current fold to the DataFrame\n",
    "        fold_top_indices_df[f'Fold_{fold}'] = top_100_indices\n",
    "\n",
    "    # Save the DataFrame as a .tsv file, including the cell type name in the filename\n",
    "    cell_type_name = str_labels[k]\n",
    "    tsv_filename = f'data/AMB/Gene_degree/{cell_type_name}_top100_indices.tsv'\n",
    "    fold_top_indices_df.to_csv(tsv_filename, sep='\\t', index=False)\n",
    "\n",
    "    print(f\"Saved top 100 indices for cell type '{cell_type_name}' to {tsv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a function to get the union of the top 100 genes from each fold in a TSV file\n",
    "def read_and_union_tsv(file_path):\n",
    "    # Read the TSV file\n",
    "    data = pd.read_csv(file_path, sep='\\t')\n",
    "    # Compute the union of all columns by combining values across folds\n",
    "    union_set = set.union(*[set(data[col].dropna().astype(int)) for col in data.columns])\n",
    "    # Return the union as a list\n",
    "    return list(union_set)\n",
    "\n",
    "# File paths for different cell types\n",
    "file1_path = 'data/AMB/Gene_degree/GABAergic_top100_indices.tsv'\n",
    "file2_path = 'data/AMB/Gene_degree/Glutamatergic_top100_indices.tsv'\n",
    "file3_path = 'data/AMB/Gene_degree/Non-Neuronal_top100_indices.tsv'\n",
    "\n",
    "# Compute the union for each cell type\n",
    "union1 = read_and_union_tsv(file1_path)\n",
    "union2 = read_and_union_tsv(file2_path)\n",
    "union3 = read_and_union_tsv(file3_path)\n",
    "\n",
    "# Print the size of each union\n",
    "print(\"Number of genes in GABAergic union:\", len(union1))\n",
    "print(\"Number of genes in Glutamatergic union:\", len(union2))\n",
    "print(\"Number of genes in Non-Neuronal union:\", len(union3))\n",
    "\n",
    "# Combine the union results into a DataFrame, ensuring the data type is integer\n",
    "result_df = pd.DataFrame({\n",
    "    'GABAergic': pd.Series(union1, dtype='Int64'),\n",
    "    'Glutamatergic': pd.Series(union2, dtype='Int64'),\n",
    "    'NonNeuronal': pd.Series(union3, dtype='Int64')\n",
    "})\n",
    "\n",
    "# Save the merged results to a new TSV file\n",
    "result_df.to_csv('data/AMB/Gene_degree/AMB_merged_top100_genes.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of edge weight on AMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from scipy import sparse\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_top_edges(matrices, top_k=100):\n",
    "    \"\"\"\n",
    "    Find the top edges with the highest average weight across multiple sparse matrices.\n",
    "    \n",
    "    Parameters:\n",
    "    matrices: List[scipy.sparse.csr_matrix] - List of sparse matrices\n",
    "    top_k: int - The number of top edges to return\n",
    "    \n",
    "    Returns:\n",
    "    List[tuple] - A list of (node1, node2, avg_weight) tuples sorted by average weight in descending order\n",
    "    \"\"\"\n",
    "    total_matrices = len(matrices)  # Total number of matrices\n",
    "    edge_weights = defaultdict(float)\n",
    "    \n",
    "    # Iterate over all matrices\n",
    "    for matrix in matrices:\n",
    "        # Get coordinates and values of non-zero elements\n",
    "        rows, cols = matrix.nonzero()\n",
    "        values = matrix.data\n",
    "        \n",
    "        # Iterate over each non-zero element\n",
    "        for i in range(len(rows)):\n",
    "            # Convert numpy integers to Python integers\n",
    "            node1 = int(min(rows[i], cols[i]))\n",
    "            node2 = int(max(rows[i], cols[i]))\n",
    "            if node1 != node2:  # Ignore self-loops\n",
    "                # Convert numpy floats to Python floats\n",
    "                edge_weights[(node1, node2)] += float(values[i])\n",
    "\n",
    "    # Compute average weight for each edge\n",
    "    edge_avg_weights = []\n",
    "    for (node1, node2), weight_sum in edge_weights.items():\n",
    "        # Ensure all values are Python native types\n",
    "        avg_weight = float(weight_sum) / float(total_matrices)\n",
    "        edge_avg_weights.append((int(node1), int(node2), float(avg_weight)))\n",
    "    \n",
    "    # Return the top k edges by average weight\n",
    "    return heapq.nlargest(top_k, edge_avg_weights, key=lambda x: x[2])\n",
    "\n",
    "\n",
    "def load_and_process_matrices(cell_test_folder, cur_label_idxs):\n",
    "    \"\"\"\n",
    "    Load sparse matrix data for the specified cells.\n",
    "    \n",
    "    Parameters:\n",
    "    file_paths: List[str] - List of sparse matrix file paths\n",
    "    \n",
    "    Returns:\n",
    "    List[scipy.sparse.csr_matrix] - List of sparse matrices\n",
    "    \"\"\"\n",
    "    matrices = []\n",
    "\n",
    "    for idx in cur_label_idxs:\n",
    "        data = torch.load(os.path.join(cell_test_folder, f'cell_{idx}.pt'))\n",
    "        # Get the current edge index and edge weight\n",
    "        edge_index = data.edge_index\n",
    "        edge_weight = data.edge_weight\n",
    "        \n",
    "        # Get the number of nodes\n",
    "        num_nodes = data.x.shape[0]  # Extract node count from feature matrix\n",
    "\n",
    "        # Convert edge_index and edge_weight to numpy arrays\n",
    "        edges = edge_index.cpu().numpy()\n",
    "        weights = edge_weight.cpu().numpy()\n",
    "\n",
    "        # Create sparse matrix from edge_index and edge_weight\n",
    "        sparse_mat = sparse.csr_matrix(\n",
    "            (weights, (edges[0], edges[1])),\n",
    "            shape=(num_nodes, num_nodes)\n",
    "        )           \n",
    "        \n",
    "        matrices.append(sparse_mat)     \n",
    "    \n",
    "    return matrices\n",
    "\n",
    "\n",
    "def save_cell_type_edges(cell_type, fold_edges, save_folder, base_filename):\n",
    "    \"\"\"\n",
    "    Save the top edges for each cell type across different folds.\n",
    "    \n",
    "    Parameters:\n",
    "    cell_type: str - The name of the cell type\n",
    "    fold_edges: dict - Dictionary containing the top edges for each fold\n",
    "    save_folder: str - Folder path where the results will be saved\n",
    "    base_filename: str - Base filename for naming the saved files\n",
    "    \"\"\"\n",
    "    # Create save directory if it doesn't exist\n",
    "    save_dir = os.path.join(save_folder, f\"{base_filename}_top_edges\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Build the file path for saving\n",
    "    filename = os.path.join(save_dir, f\"{cell_type}_top_edges.npz\")\n",
    "    \n",
    "    # Prepare dictionary for saving data\n",
    "    save_dict = {\n",
    "        'cell_type': cell_type,\n",
    "        'base_filename': base_filename\n",
    "    }\n",
    "    \n",
    "    # Add top edges for each fold to the dictionary\n",
    "    for fold_idx, edges in fold_edges.items():\n",
    "        # Convert edges to numpy array and ensure proper data types\n",
    "        edges_array = np.array(edges, dtype=[\n",
    "            ('node1', 'int32'), \n",
    "            ('node2', 'int32'), \n",
    "            ('weight', 'float32')\n",
    "        ])\n",
    "        save_dict[f'fold_{fold_idx}_edges'] = edges_array        \n",
    "    \n",
    "    # Save the data as a .npz file\n",
    "    np.savez(filename, **save_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_label:  0\n",
      "cell_type:  GABAergic\n",
      "cur_label:  1\n",
      "cell_type:  Glutamatergic\n",
      "cur_label:  2\n",
      "cell_type:  Non-Neuronal\n"
     ]
    }
   ],
   "source": [
    "seq_dict = np.load('../../dataset/5fold_data/AMB/seq_dict.npz', allow_pickle=True) \n",
    "label = seq_dict['label'] \n",
    "str_labels = seq_dict['str_labels']\n",
    "save_folder = 'data/AMB/Gene_degree/'\n",
    "\n",
    "cell_type_edges = {}\n",
    "\n",
    "for cur_label, cell_type in enumerate(str_labels):\n",
    "    print(\"cur_label: \", cur_label)\n",
    "    print(\"cell_type: \", cell_type)\n",
    "    fold_edges = {}\n",
    "    \n",
    "    for k in range(5):\n",
    "        k_fold = k + 1\n",
    "        test_index = seq_dict[f'test_index_{k_fold}']\n",
    "        label_test = label[test_index]\n",
    "        cur_label_idxs = np.where(label_test == cur_label)[0].tolist()\n",
    "\n",
    "        cell_test_folder = os.path.join(\n",
    "            \"../../dataset/5fold_data/AMB/wcsn_a0.01_hvgs2000\", \n",
    "            f\"test_f{k_fold}\", \n",
    "            'processed'\n",
    "        )\n",
    "        \n",
    "        cur_mat = load_and_process_matrices(cell_test_folder, cur_label_idxs)\n",
    "        cur_top_edges = find_top_edges(cur_mat)\n",
    "        \n",
    "        fold_edges[k_fold] = cur_top_edges\n",
    "\n",
    "    save_cell_type_edges(cell_type, fold_edges, save_folder,  base_filename=\"AMB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert npz data into R-readable format\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = np.load('data/AMB/AMB_top_edges/Non-Neuronal_top_edges.npz', allow_pickle=True)\n",
    "\n",
    "def create_edge_strings(edges):\n",
    "    return [f\"{int(edge[0])}-{int(edge[1])}\" for edge in edges]\n",
    "\n",
    "os.makedirs('data/AMB/AMB_top_edges/NonNeuronal_top_edges',exist_ok=True)\n",
    "\n",
    "fold_edges = {}\n",
    "for i in range(1, 6):  # 5折\n",
    "    fold_key = f'fold_{i}_edges'\n",
    "    if fold_key in data:\n",
    "        edges = data[fold_key]\n",
    "        edge_strings = create_edge_strings(edges)\n",
    "        pd.DataFrame({'edges': edge_strings}).to_csv(f'data/AMB/AMB_top_edges/NonNeuronal_top_edges/fold_{i}_edges.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert npz data into R-readable format\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = np.load('data/AMB/AMB_top_edges/Glutamatergic_top_edges.npz', allow_pickle=True)\n",
    "\n",
    "def create_edge_strings(edges):\n",
    "    return [f\"{int(edge[0])}-{int(edge[1])}\" for edge in edges]\n",
    "\n",
    "os.makedirs('data/AMB/AMB_top_edges/Glutamatergic_top_edges',exist_ok=True)\n",
    "\n",
    "fold_edges = {}\n",
    "for i in range(1, 6): \n",
    "    fold_key = f'fold_{i}_edges'\n",
    "    if fold_key in data:\n",
    "        edges = data[fold_key]\n",
    "        edge_strings = create_edge_strings(edges)\n",
    "        if not os.path.exists('data/AMB/AMB_top_edges/Glutamatergic_top_edges/'):\n",
    "            os.makedirs('data/AMB/AMB_top_edges/Glutamatergic_top_edges/', exist_ok=True)         \n",
    "        pd.DataFrame({'edges': edge_strings}).to_csv(f'data/AMB/AMB_top_edges/Glutamatergic_top_edges/fold_{i}_edges.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert npz data into R-readable format\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = np.load('data/AMB/AMB_top_edges/GABAergic_top_edges.npz', allow_pickle=True)\n",
    "\n",
    "def create_edge_strings(edges):\n",
    "    return [f\"{int(edge[0])}-{int(edge[1])}\" for edge in edges]\n",
    "\n",
    "os.makedirs('data/AMB/AMB_top_edges/GABAergic_top_edges',exist_ok=True)\n",
    "\n",
    "fold_edges = {}\n",
    "for i in range(1, 6): \n",
    "    fold_key = f'fold_{i}_edges'\n",
    "    if fold_key in data:\n",
    "        edges = data[fold_key]\n",
    "        edge_strings = create_edge_strings(edges)\n",
    "        if not os.path.exists('data/AMB/AMB_top_edges/GABAergic_top_edges/'):\n",
    "            os.makedirs('data/AMB/AMB_top_edges/GABAergic_top_edges/', exist_ok=True)         \n",
    "        pd.DataFrame({'edges': edge_strings}).to_csv(f'data/AMB/AMB_top_edges/GABAergic_top_edges/fold_{i}_edges.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_union_edges(npz_file):\n",
    "   data = np.load(npz_file, allow_pickle=True)\n",
    "   \n",
    "   all_edges = set()\n",
    "   \n",
    "   # 遍历5折\n",
    "   for i in range(1, 6):\n",
    "       fold_key = f'fold_{i}_edges'\n",
    "       if fold_key in data:\n",
    "           edges = data[fold_key]\n",
    "           edge_strings = [f\"{int(edge[0])}-{int(edge[1])}\" for edge in edges]\n",
    "           all_edges.update(edge_strings)\n",
    "   print(list(all_edges))\n",
    "   return sorted(list(all_edges))  \n",
    "\n",
    "cell_types = ['GABAergic','Glutamatergic', 'Non-Neuronal'] \n",
    "edges_dict = {}\n",
    "\n",
    "for cell_type in cell_types:\n",
    "   npz_file = f'data/AMB/AMB_top_edges/{cell_type}_top_edges.npz' \n",
    "   if os.path.exists(npz_file):\n",
    "        edges_dict[cell_type] = get_union_edges(npz_file)\n",
    "\n",
    "\n",
    "max_length = max(len(edges) for edges in edges_dict.values())\n",
    "\n",
    "for cell_type in edges_dict:\n",
    "   if len(edges_dict[cell_type]) < max_length:\n",
    "       edges_dict[cell_type].extend([''] * (max_length - len(edges_dict[cell_type])))\n",
    "\n",
    "df = pd.DataFrame(edges_dict)\n",
    "print(df.columns)\n",
    "\n",
    "df.columns = ['GABAergic', 'Glutamatergic', 'NonNeuronal']\n",
    "\n",
    "save_path = 'data/AMB/AMB_top_edges/union_edges.tsv'\n",
    "df.to_csv(save_path, sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p38tor112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
